{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset (assuming it's in CSV format)\n",
    "df = pd.read_csv('Emotional-Tone-Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10065 entries, 0 to 10064\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   ID      10065 non-null  int64 \n",
      " 1    TWEET  10064 non-null  object\n",
      " 2    LABEL  10065 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 236.0+ KB\n",
      "None\n",
      "\n",
      "First few rows of the dataset:\n",
      "   ID                                              TWEET    LABEL\n",
      "0   1            Ø§Ù„Ø§ÙˆÙ„ÙŠÙ…Ø¨ÙŠØ§Ø¯ Ø§Ù„Ø¬Ø§ÙŠÙ‡ Ù‡ÙƒÙˆÙ† Ù„Ø³Ù‡ Ù Ø§Ù„ÙƒÙ„ÙŠÙ‡ ..     none\n",
      "1   2  Ø¹Ø¬Ø² Ø§Ù„Ù…ÙˆØ§Ø²Ù†Ù‡ ÙˆØµÙ„ Ù„93.7 % Ù…Ù† Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù…Ø­Ù„ÙŠ ÙŠØ¹Ù†ÙŠ...    anger\n",
      "2   3                         ÙƒØªÙ†Ø§ Ù†ÙŠÙ„Ù‡ Ù Ø­Ø¸Ù†Ø§ Ø§Ù„Ù‡Ø¨Ø§Ø¨ xD  sadness\n",
      "3   4  Ø¬Ù…ÙŠØ¹Ù†Ø§ Ù†Ø±ÙŠØ¯ ØªØ­Ù‚ÙŠÙ‚ Ø§Ù‡Ø¯Ø§ÙÙ†Ø§ Ù„ÙƒÙ† ØªÙˆÙ†Ø³ ØªØ§Ù„Ù‚Øª ÙÙŠ Ø­Ø±...      joy\n",
      "4   5  Ø§Ù„Ø§ÙˆÙ„ÙŠÙ…Ø¨ÙŠØ§Ø¯ Ù†Ø¸Ø§Ù…Ù‡Ø§ Ù…Ø®ØªÙ„Ù .. ÙˆÙ…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙˆÙ†Ø¯ÙŠØ§Ù„ ...     none\n",
      "Index(['ID', ' TWEET', ' LABEL'], dtype='object')\n",
      "Index(['ID', 'TWEET', 'LABEL'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Explore the dataset\n",
    "print(\"Dataset information:\")\n",
    "print(df.info())\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "df.isnull().any()\n",
    "\n",
    "# Rename Columns\n",
    "print(df.columns)\n",
    "df.rename(columns={' ID': 'ID', ' TWEET': 'TWEET', ' LABEL': 'LABEL'}, inplace=True)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the ID column\n",
    "df.drop(['ID'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TWEET</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ø§Ù„Ø§ÙˆÙ„ÙŠÙ…Ø¨ÙŠØ§Ø¯ Ø§Ù„Ø¬Ø§ÙŠÙ‡ Ù‡ÙƒÙˆÙ† Ù„Ø³Ù‡ Ù Ø§Ù„ÙƒÙ„ÙŠÙ‡ ..</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ø¹Ø¬Ø² Ø§Ù„Ù…ÙˆØ§Ø²Ù†Ù‡ ÙˆØµÙ„ Ù„93.7 % Ù…Ù† Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù…Ø­Ù„ÙŠ ÙŠØ¹Ù†ÙŠ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ÙƒØªÙ†Ø§ Ù†ÙŠÙ„Ù‡ Ù Ø­Ø¸Ù†Ø§ Ø§Ù„Ù‡Ø¨Ø§Ø¨ xD</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Ø¬Ù…ÙŠØ¹Ù†Ø§ Ù†Ø±ÙŠØ¯ ØªØ­Ù‚ÙŠÙ‚ Ø§Ù‡Ø¯Ø§ÙÙ†Ø§ Ù„ÙƒÙ† ØªÙˆÙ†Ø³ ØªØ§Ù„Ù‚Øª ÙÙŠ Ø­Ø±...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ø§Ù„Ø§ÙˆÙ„ÙŠÙ…Ø¨ÙŠØ§Ø¯ Ù†Ø¸Ø§Ù…Ù‡Ø§ Ù…Ø®ØªÙ„Ù .. ÙˆÙ…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙˆÙ†Ø¯ÙŠØ§Ù„ ...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10060</th>\n",
       "      <td>10061</td>\n",
       "      <td>2222: ÙŠÙ„Ø§ ÙŠØ§ Ø¬Ù…Ø§Ø¹Ù‡ Ø­ÙÙ„Ù‡ Ø¹Ù…Ø±Ùˆ Ø¯ÙŠØ§Ø¨ Ø®Ù„ØµØª Ù†Ø±ÙŠØ­ Ø´Ùˆ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10061</th>\n",
       "      <td>10062</td>\n",
       "      <td>Mohamed5: Ø§ÙŠÙŠÙŠÙŠÙ‡ Ø¯Ø§Ø§Ø§ ğŸ˜²ğŸ˜² Ø§ÙˆØ²ÙŠÙŠÙŠÙ„â¤</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10062</th>\n",
       "      <td>10063</td>\n",
       "      <td>Ø¹Ù…Ù„ØªÙ„Ù‡Ø§ Ø±ÙŠØªÙˆÙŠØª Ø¨Ù…Ù†Ø§Ø³Ø¨Ù‡ Ø³Ø§Ø±Ù‡ Ø¨ØªØ§Ø¹Ù‡ Ø§Ù„Ø§ÙˆÙ„ÙŠÙ…Ø¨ÙŠØ§Ø¯ ğŸ˜ƒ</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10063</th>\n",
       "      <td>10064</td>\n",
       "      <td>ÙˆØ¹Ù„ÙŠÙƒ Ù‚Ø¨Ù„Ù†Ø§ ÙŠØ§Ù†Ø¬Ù… Ø§Ù„Ù†Ø¬ÙˆÙ… ÙŠØ§Ø¹Ù†Ø¯Ù„ÙŠØ¨ Ø§Ù„Ø­Ø¨ ÙˆØ§Ù„Ø§Ø­Ø³Ø§Ø³</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10064</th>\n",
       "      <td>10065</td>\n",
       "      <td>AlHamad ÙŠØ·Ù„Ø¹ Ù†Ù†Ù‡Ù… ÙƒÙ„ Ø´ÙŠ Ø³ÙŠØ¡ ÙˆÙˆØ¶ÙŠØ¹ ÙƒÙ„ Ø®Ø³Ø§Ø³Ù‡ Ø§Ù„Ø¹...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10065 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                              TWEET     LABEL\n",
       "0          1            Ø§Ù„Ø§ÙˆÙ„ÙŠÙ…Ø¨ÙŠØ§Ø¯ Ø§Ù„Ø¬Ø§ÙŠÙ‡ Ù‡ÙƒÙˆÙ† Ù„Ø³Ù‡ Ù Ø§Ù„ÙƒÙ„ÙŠÙ‡ ..      none\n",
       "1          2  Ø¹Ø¬Ø² Ø§Ù„Ù…ÙˆØ§Ø²Ù†Ù‡ ÙˆØµÙ„ Ù„93.7 % Ù…Ù† Ø§Ù„Ù†Ø§ØªØ¬ Ø§Ù„Ù…Ø­Ù„ÙŠ ÙŠØ¹Ù†ÙŠ...     anger\n",
       "2          3                         ÙƒØªÙ†Ø§ Ù†ÙŠÙ„Ù‡ Ù Ø­Ø¸Ù†Ø§ Ø§Ù„Ù‡Ø¨Ø§Ø¨ xD   sadness\n",
       "3          4  Ø¬Ù…ÙŠØ¹Ù†Ø§ Ù†Ø±ÙŠØ¯ ØªØ­Ù‚ÙŠÙ‚ Ø§Ù‡Ø¯Ø§ÙÙ†Ø§ Ù„ÙƒÙ† ØªÙˆÙ†Ø³ ØªØ§Ù„Ù‚Øª ÙÙŠ Ø­Ø±...       joy\n",
       "4          5  Ø§Ù„Ø§ÙˆÙ„ÙŠÙ…Ø¨ÙŠØ§Ø¯ Ù†Ø¸Ø§Ù…Ù‡Ø§ Ù…Ø®ØªÙ„Ù .. ÙˆÙ…ÙˆØ§Ø¹ÙŠØ¯ Ø§Ù„Ù…ÙˆÙ†Ø¯ÙŠØ§Ù„ ...      none\n",
       "...      ...                                                ...       ...\n",
       "10060  10061  2222: ÙŠÙ„Ø§ ÙŠØ§ Ø¬Ù…Ø§Ø¹Ù‡ Ø­ÙÙ„Ù‡ Ø¹Ù…Ø±Ùˆ Ø¯ÙŠØ§Ø¨ Ø®Ù„ØµØª Ù†Ø±ÙŠØ­ Ø´Ùˆ...   sadness\n",
       "10061  10062                  Mohamed5: Ø§ÙŠÙŠÙŠÙŠÙ‡ Ø¯Ø§Ø§Ø§ ğŸ˜²ğŸ˜² Ø§ÙˆØ²ÙŠÙŠÙŠÙ„â¤  surprise\n",
       "10062  10063    Ø¹Ù…Ù„ØªÙ„Ù‡Ø§ Ø±ÙŠØªÙˆÙŠØª Ø¨Ù…Ù†Ø§Ø³Ø¨Ù‡ Ø³Ø§Ø±Ù‡ Ø¨ØªØ§Ø¹Ù‡ Ø§Ù„Ø§ÙˆÙ„ÙŠÙ…Ø¨ÙŠØ§Ø¯ ğŸ˜ƒ      none\n",
       "10063  10064    ÙˆØ¹Ù„ÙŠÙƒ Ù‚Ø¨Ù„Ù†Ø§ ÙŠØ§Ù†Ø¬Ù… Ø§Ù„Ù†Ø¬ÙˆÙ… ÙŠØ§Ø¹Ù†Ø¯Ù„ÙŠØ¨ Ø§Ù„Ø­Ø¨ ÙˆØ§Ù„Ø§Ø­Ø³Ø§Ø³       joy\n",
       "10064  10065  AlHamad ÙŠØ·Ù„Ø¹ Ù†Ù†Ù‡Ù… ÙƒÙ„ Ø´ÙŠ Ø³ÙŠØ¡ ÙˆÙˆØ¶ÙŠØ¹ ÙƒÙ„ Ø®Ø³Ø§Ø³Ù‡ Ø§Ù„Ø¹...     anger\n",
       "\n",
       "[10065 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from stopwords import stop_words_ar\n",
    "\n",
    "############### initial variables and lists ##################\n",
    "\n",
    "arabic_punctuations = '''`Ã·Ã—Ø›<>_()*&^%][Ù€ØŒ/:\"ØŸ.,'{}~Â¦+|!â€â€¦â€œâ€“Ù€'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "\n",
    "arabic_diacritics = re.compile(\"\"\"\n",
    "                             Ù‘    | # Tashdid\n",
    "                             Ù    | # Fatha\n",
    "                             Ù‹    | # Tanwin Fath\n",
    "                             Ù    | # Damma\n",
    "                             ÙŒ    | # Tanwin Damm\n",
    "                             Ù    | # Kasra\n",
    "                             Ù    | # Tanwin Kasr\n",
    "                             Ù’    | # Sukun\n",
    "                             Ù€     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "arabic_handles = \\\n",
    "    [\n",
    "        ('Ù‡', ['Ø©']),\\\n",
    "        ('ÙŠ', ['Ù‰']),\\\n",
    "        ('Ø§', ['Ø£','Ø¥','Ø¢']),\\\n",
    "        # ('Ùˆ', ['Ø¤']),\\\n",
    "        ('', ['Ù‘','â€˜','ÙŒ','Ù','Ù‹','Ù','Ù','Ù','Ù€','â€™','Ù’','~'])\n",
    "    ]\n",
    "\n",
    "############### functions ##################\n",
    "def clean_text(text):\n",
    "    \"\"\" \n",
    "    It includes these functions:\n",
    "        1-remove_emails\n",
    "        2-remove_URLs\n",
    "        3-remove_mentions\n",
    "        4-hashtags_to_words\n",
    "        5-remove_punctuationsb\n",
    "        6-normalize_arabic\n",
    "        7-remove_diacritics\n",
    "        8-remove_repeating_char\n",
    "        9- remove newlines\n",
    "        10-remove_stop_words\n",
    "        11-remove_emojis\n",
    "        12-remove_english_characters\n",
    "        13-remove_digits\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        return ''  # Return an empty string for non-string values\n",
    "    \n",
    "    text=remove_emails(text)\n",
    "    text=remove_URLs(text)\n",
    "    text=remove_mentions(text)\n",
    "    text= hashtags_to_words(text)\n",
    "    text=remove_punctuations(text)\n",
    "    text= remove_newlines(text)\n",
    "    text=normalize_arabic(text)\n",
    "    text=remove_diacritics(text)\n",
    "    text=remove_stop_words(text)\n",
    "    text=replace_emojis(text)\n",
    "    text=remove_english_characters(text)\n",
    "    text=remove_digits(text)\n",
    "    text=remove_repeating_char(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def normalize_arabic(text):\n",
    "    \"\"\" normalize the arabic character  .\"\"\"\n",
    "    text = re.sub(\"[Ø¥Ø£Ø¢Ø§]\", \"Ø§\", text)\n",
    "    text = re.sub(\"Ù‰\", \"ÙŠ\", text)\n",
    "    text = re.sub(\"Ø¤\", \"Ø¡\", text)\n",
    "    text = re.sub(\"Ø¦\", \"Ø¡\", text)\n",
    "    text = re.sub(\"Ø©\", \"Ù‡\", text)\n",
    "    text = re.sub(\"Ú¯\", \"Ùƒ\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_digits(word_list):\n",
    "    # Remove digits\n",
    "    filtered_words = ''.join([w for w in word_list if not w.isdigit()])\n",
    "    return filtered_words\n",
    "\n",
    "def remove_diacritics(text):\n",
    "    \"\"\" remove the `arabic diacritics` from the `text` .\"\"\"\n",
    "    text = re.sub(arabic_diacritics, '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    \"\"\" remove the `punctuations` from the `text` .\"\"\"\n",
    "    translator = str.maketrans('', '', punctuations_list)\n",
    "    return text.translate(translator)\n",
    "\n",
    "\n",
    "def remove_repeating_char(text):\n",
    "    \"\"\" remove the `repeating character` from the `text` .\"\"\"\n",
    "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
    "\n",
    "def remove_newlines(text):\n",
    "  text = re.sub('\\n',\" . \",text)\n",
    "  return text\n",
    "\n",
    "def read_stop_words():\n",
    "    \"\"\" read the `stopwords` \"\"\"\n",
    "    stop_words = stop_words_ar.split('\\n')\n",
    "    #unify arabic letters\n",
    "    for key, arr in arabic_handles:\n",
    "        for a in arr:\n",
    "            stop_words = [word.replace(a, key) for word in stop_words] \n",
    "    return stop_words\n",
    "\n",
    "def remove_english_characters(text):\n",
    "    # Define a regular expression pattern to match English characters\n",
    "    english_pattern = re.compile(\"[a-zA-Z]\")\n",
    "\n",
    "    # Use sub to replace English characters with an empty string\n",
    "    cleaned_text = english_pattern.sub('', text)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\" remove the `list of Arabic stopwords` from the `text` .\"\"\"\n",
    "    stop_words = read_stop_words()\n",
    "    lines = text.splitlines()\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        if line.strip():  #if not empty\n",
    "            words = line.split()\n",
    "            for w in range(0, len(words)):\n",
    "                word = words[w]\n",
    "                if word in stop_words:\n",
    "                    words[w] = \"\"\n",
    "            line = \" \".join(words)\n",
    "            line = line.replace(\"  \",\" \")\n",
    "            new_lines.append(line)\n",
    "    return '\\n'.join(new_lines)\n",
    "\n",
    "def remove_URLs(text): \n",
    "    \"\"\" remove the `URLs` from the `text` .\"\"\"\n",
    "    text =re.sub(r\"(?:http?\\://|https?\\://|www)\\S+\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def remove_emails(text):\n",
    "    \"\"\" remove the `emails` from the `text` .\"\"\"\n",
    "    text = re.sub(r'[\\w\\.-]+@[\\w\\.-]+',\"\",text)\n",
    "    return text\n",
    "\n",
    "def remove_mentions(text):\n",
    "    \"\"\" remove the `mentions` from the `text` .\"\"\"\n",
    "    text = re.sub(r\"@([A-Za-z0-9_-]+)\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def hashtags_to_words(text):\n",
    "    \"\"\" convert any `hashtags` to  `words` .\"\"\"\n",
    "    text = re.sub(r'#', \"\", text)\n",
    "    text = re.sub(r\"_\", \"  \", text)\n",
    "    return text\n",
    "\n",
    "def replace_emojis(text): \n",
    "    text = re.sub(r'<3|< 3|â¤ï¸|ğŸ’–|ğŸ˜|ğŸ’•|ğŸ˜˜|ğŸ¥°|ğŸ’•|ğŸ’|ğŸ’—|ğŸ’œ|ğŸ’™|ğŸ–¤|ğŸ’š|ğŸ’›|ğŸ¤|â¤',\n",
    "                  ' Ù‚Ù„Ø¨ ',\n",
    "                  text) \n",
    "\n",
    "    text = re.sub(r':P|:-P|ğŸ˜‚|ğŸ¤£',\n",
    "                  ' Ø¶Ø­Ùƒ ',\n",
    "                  text)\n",
    "\n",
    "    text = re.sub(r'[â˜ºğŸ˜ŒğŸ˜ğŸ˜ƒğŸ˜„ğŸ˜†ğŸ˜ŠğŸ˜¸ğŸ˜ºğŸ˜ŠğŸ˜€ğŸ˜‹â˜ºï¸ğŸ™‚ğŸ’ƒ]',\n",
    "                  ' Ø³Ø¹Ø§Ø¯Ø© ',\n",
    "                  text)\n",
    "    \n",
    "    \n",
    "    text = re.sub(r':D',\n",
    "                  ' Ø³Ø¹Ø§Ø¯Ø© ',\n",
    "                  text)\n",
    "\n",
    "    text = re.sub(r'[ğŸ˜¥ğŸ˜£ğŸ˜“ğŸ˜”ğŸ˜•â˜¹ï¸ğŸ™ğŸ˜–ğŸ˜ğŸ˜ŸğŸ˜¢ğŸ˜­ğŸ˜©ğŸ˜¿ğŸ˜«ğŸ˜©ğŸ’”]',\n",
    "                  ' Ø­Ø²Ù†  ',\n",
    "                  text)\n",
    "    text = re.sub(r'(::|\\)-:)',\n",
    "                  '  Ø­Ø²Ù†  ', \n",
    "                  text)\n",
    "    text = re.sub(r'(:,\\(|:\\'\\(|:\"\\()',\n",
    "                  ' Ø­Ø²Ù† ', \n",
    "                  text)\n",
    "\n",
    "    text = re.sub(r'[ğŸ˜¨ğŸ˜±ğŸ˜µ]',\n",
    "                  ' Ù…ÙØ§Ø¬Ø£Ø© ', \n",
    "                  text)\n",
    "\n",
    "    text = re.sub(r'[ğŸ˜³ğŸ˜…ğŸ™ˆ]',\n",
    "                  ' Ù…Ø­Ø±Ø¬ ', \n",
    "                  text)\n",
    "\n",
    "    text = re.sub(r'[ğŸ˜¤ğŸ˜ ğŸ˜¡ğŸ¤¬ğŸ‘¿]',\n",
    "                  ' ØºØ¶Ø¨ ', \n",
    "                  text)\n",
    "\n",
    "    text = re.sub(r'[ğŸ˜‘ğŸ˜’ğŸ™„ğŸ˜ğŸ˜¶]',\n",
    "                  ' Ù…Ù„Ù„ ', \n",
    "                  text)\n",
    "\n",
    "    text = re.sub('[\\U0001F600-\\U0001FFFF]',\" \", text)\n",
    "    text = re.sub('[\\U0001F300-\\U0001F5FF]',\" \", text)\n",
    "    text = re.sub('[\\U0001F680-\\U0001F6FF]',\" \", text)\n",
    "    text = re.sub('[\"\\U0001F1E0-\\U0001F1FF]',\" \", text)\n",
    "\n",
    "    \n",
    "    weirdPatterns = re.compile(\"[\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u'\\U00010000-\\U0010ffff'\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\u3030\"\n",
    "                               u\"\\ufe0f\"\n",
    "                               u\"\\u2069\"\n",
    "                               u\"\\u2066\"\n",
    "                               u\"\\u200c\"\n",
    "                               u\"\\u2068\"\n",
    "                               u\"\\u2067\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    text = weirdPatterns.sub(r'', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization & Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stemming(text):\n",
    "    stemmer = nltk.ISRIStemmer()\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    #stemming\n",
    "    word_list = [stemmer.stem(w) for w in  word_list]\n",
    "    return ' '.join(word_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    tweet = df.at[i, 'TWEET']\n",
    "    \n",
    "    # Check if tweet is a string\n",
    "    if isinstance(tweet, str):\n",
    "        cleaned_tweet = clean_text(tweet)\n",
    "        stemmed_tweet = tokenize_and_stemming(cleaned_tweet)\n",
    "        df.at[i, 'TWEET'] = stemmed_tweet\n",
    "    else:\n",
    "        # Handle non-string values (e.g., empty strings or other types)\n",
    "        df.at[i, 'TWEET'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TWEET</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ø§ÙˆÙ„ÙŠÙ…Ø¨ÙŠØ§Ø¯ Ø¬ÙŠÙ‡ Ù‡ÙƒÙ† Ù„Ø³Ù‡ ÙƒÙ„Ù‡</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ø¹Ø¬Ø² ÙˆØ²Ù† ÙˆØµÙ„ Ù„ Ù†ØªØ¬ Ø­Ù„ÙŠ ÙŠØ¹Ù† Ù„Ø³Ù‡ Ø§Ù‚Ù„ ÙÙ„Ø³ Ù‡ÙŠÙ… Ù„Ø³Ù‡ ...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ÙƒØªÙ† Ù†ÙŠÙ„ Ø­Ø¸Ù† Ù‡Ø¨Ø¨</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Ø¬Ù…Ø¹ Ù†Ø±Ø¯ Ø­Ù‚Ù‚ Ù‡Ø¯Ù ÙˆÙ†Ø³ ØªÙ„Ù‚ Ø­Ø±Ø³ Ø±Ù…ÙŠ</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ø§ÙˆÙ„ÙŠÙ…Ø¨ÙŠØ§Ø¯ Ù†Ø¸Ù… Ø®Ù„Ù Ù…ÙˆØ§Ø¹ÙŠØ¯ Ù…ÙˆÙ†Ø¯ÙŠØ§Ù„ Ù…ÙƒØ§Ù†ØªØ´ Ù‚Ø±Ù Ø­Ø¬...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10060</th>\n",
       "      <td>10061</td>\n",
       "      <td>ÙŠÙ„Ø§ Ø¬Ù…Ø¹ Ø­ÙÙ„ Ø¹Ù…Ø±Ùˆ Ø¯ÙŠØ¨ Ø®Ù„Øµ Ù†Ø±Ø­ Ø´ÙˆÙ‡ Ù†Ø¨Ø¯ ÙƒØªØ¡Ø¨ Ø¹Ø´Ù… ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10061</th>\n",
       "      <td>10062</td>\n",
       "      <td>Ø§ÙŠÙ‡ Ø¯Ø§ ÙˆØ²Ù„ Ù‚Ù„Ø¨</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10062</th>\n",
       "      <td>10063</td>\n",
       "      <td>Ø¹Ù…Ù„ØªÙ„ Ø±ÙŠØªÙˆ Ù†Ø³Ø¨ Ø³Ø±Ù‡ Ø¨ØªØ¹ Ø§ÙˆÙ„ÙŠÙ…Ø¨ÙŠØ§Ø¯ Ø³Ø¹Ø¯</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10063</th>\n",
       "      <td>10064</td>\n",
       "      <td>Ù‚Ø¨Ù„ Ù†Ø¬Ù… Ù†Ø¬Ù… ÙŠØ§Ø¹Ù†Ø¯Ù„ÙŠØ¨ Ù„Ø­Ø¨ Ø­Ø³Ø³</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10064</th>\n",
       "      <td>10065</td>\n",
       "      <td>Ø·Ù„Ø¹ Ù†Ù‡Ù… Ø´ÙŠ Ø³ÙŠØ¡ ÙˆØ¶Ø¹ Ø®Ø³Ø³ Ø¹Ù„Ù… Ø¬Ù…Ø¹ ÙŠØ±Ù† Ø§Ù„ÙŠ Ù„ÙØª Ø¨Ø­Ø±...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10065 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                              TWEET     LABEL\n",
       "0          1                          Ø§ÙˆÙ„ÙŠÙ…Ø¨ÙŠØ§Ø¯ Ø¬ÙŠÙ‡ Ù‡ÙƒÙ† Ù„Ø³Ù‡ ÙƒÙ„Ù‡      none\n",
       "1          2  Ø¹Ø¬Ø² ÙˆØ²Ù† ÙˆØµÙ„ Ù„ Ù†ØªØ¬ Ø­Ù„ÙŠ ÙŠØ¹Ù† Ù„Ø³Ù‡ Ø§Ù‚Ù„ ÙÙ„Ø³ Ù‡ÙŠÙ… Ù„Ø³Ù‡ ...     anger\n",
       "2          3                                    ÙƒØªÙ† Ù†ÙŠÙ„ Ø­Ø¸Ù† Ù‡Ø¨Ø¨   sadness\n",
       "3          4                    Ø¬Ù…Ø¹ Ù†Ø±Ø¯ Ø­Ù‚Ù‚ Ù‡Ø¯Ù ÙˆÙ†Ø³ ØªÙ„Ù‚ Ø­Ø±Ø³ Ø±Ù…ÙŠ       joy\n",
       "4          5  Ø§ÙˆÙ„ÙŠÙ…Ø¨ÙŠØ§Ø¯ Ù†Ø¸Ù… Ø®Ù„Ù Ù…ÙˆØ§Ø¹ÙŠØ¯ Ù…ÙˆÙ†Ø¯ÙŠØ§Ù„ Ù…ÙƒØ§Ù†ØªØ´ Ù‚Ø±Ù Ø­Ø¬...      none\n",
       "...      ...                                                ...       ...\n",
       "10060  10061  ÙŠÙ„Ø§ Ø¬Ù…Ø¹ Ø­ÙÙ„ Ø¹Ù…Ø±Ùˆ Ø¯ÙŠØ¨ Ø®Ù„Øµ Ù†Ø±Ø­ Ø´ÙˆÙ‡ Ù†Ø¨Ø¯ ÙƒØªØ¡Ø¨ Ø¹Ø´Ù… ...   sadness\n",
       "10061  10062                                     Ø§ÙŠÙ‡ Ø¯Ø§ ÙˆØ²Ù„ Ù‚Ù„Ø¨  surprise\n",
       "10062  10063               Ø¹Ù…Ù„ØªÙ„ Ø±ÙŠØªÙˆ Ù†Ø³Ø¨ Ø³Ø±Ù‡ Ø¨ØªØ¹ Ø§ÙˆÙ„ÙŠÙ…Ø¨ÙŠØ§Ø¯ Ø³Ø¹Ø¯      none\n",
       "10063  10064                       Ù‚Ø¨Ù„ Ù†Ø¬Ù… Ù†Ø¬Ù… ÙŠØ§Ø¹Ù†Ø¯Ù„ÙŠØ¨ Ù„Ø­Ø¨ Ø­Ø³Ø³       joy\n",
       "10064  10065  Ø·Ù„Ø¹ Ù†Ù‡Ù… Ø´ÙŠ Ø³ÙŠØ¡ ÙˆØ¶Ø¹ Ø®Ø³Ø³ Ø¹Ù„Ù… Ø¬Ù…Ø¹ ÙŠØ±Ù† Ø§Ù„ÙŠ Ù„ÙØª Ø¨Ø­Ø±...     anger\n",
       "\n",
       "[10065 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.LABEL.value_counts()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
